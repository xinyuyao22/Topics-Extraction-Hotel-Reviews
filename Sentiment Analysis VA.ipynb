{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# nlp libraries/api\n",
    "import en_core_web_lg\n",
    "from spacy import displacy\n",
    "import gensim\n",
    "#from neuralcoref import Coref\n",
    "\n",
    "spacy = en_core_web_lg.load()\n",
    "#coref = Coref(nlp=spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load opinion lexicon\n",
    "neg_file = open(\"neg_words.txt\",encoding = \"ISO-8859-1\")\n",
    "pos_file = open(\"pos_words.txt\",encoding = \"ISO-8859-1\")\n",
    "neg = [line.strip() for line in neg_file.readlines()]\n",
    "pos = [line.strip() for line in pos_file.readlines()]\n",
    "opinion_words = neg + pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_similarity(aspects, word):\n",
    "    '''\n",
    "    checks for word2vec similarity values between category word and the term\n",
    "    returns most similar word\n",
    "    '''\n",
    "    similarity = []\n",
    "    for aspect in aspects:\n",
    "        similarity.append(word2vec.n_similarity([aspect], word.split()))\n",
    "    # set threshold for max value\n",
    "    if max(similarity) > 0.2:\n",
    "        return aspects[np.argmax(similarity)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def assign_term_to_aspect(aspect_sent, terms_dict, sent_dict, pred):\n",
    "    '''\n",
    "    function: takes in a sentiment dictionary and appends the aspect dictionary\n",
    "    inputs: sent_dict is a Counter in the form Counter(term:sentiment value)\n",
    "            aspect_sent is total sentiment tally\n",
    "            terms_dict is dict with individual aspect words associated with sentiment\n",
    "    output: return two types of aspect dictionaries:\n",
    "            updated terms_dict and aspect_sent\n",
    "    '''\n",
    "    aspects = ['location', 'checkin', 'food', 'building', 'room', 'cleanliness', 'value', 'service', 'business']\n",
    "\n",
    "    # First, check word2vec\n",
    "    # Note: the .split() is used for the term because word2vec can't pass compound nouns\n",
    "    for term in sent_dict:\n",
    "        try:\n",
    "            # The conditions for when to use the NB classifier as default vs word2vec\n",
    "            aspect = check_similarity(aspects, term)\n",
    "            if aspect:\n",
    "                terms_dict[aspect.upper()][term] += sent_dict[term]\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[aspect.upper()][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[aspect.upper()][\"neg\"] += abs(sent_dict[term])\n",
    "            elif pred:\n",
    "                aspect = str(pred[0]).strip(\"(',)\")\n",
    "                terms_dict[aspect.upper()][term] += sent_dict[term]\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[aspect.upper()][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[aspect.upper()][\"neg\"] += abs(sent_dict[term])\n",
    "            # if unable to classify via NB or word2vec, then put them in misc. bucket\n",
    "            else:\n",
    "                terms_dict[\"OTHER\"][term] += sent_dict[term]\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[\"OTHER\"][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[\"OTHER\"][\"neg\"] += abs(sent_dict[term])\n",
    "        except:\n",
    "            print(term, \"not in vocab\")\n",
    "            continue\n",
    "    return aspect_sent, terms_dict\n",
    "\n",
    "\n",
    "def modify_sentiment(token, sentiment):\n",
    "    for child in token.children:\n",
    "        # if there's a adj modifier (i.e. very, pretty, etc.) add more weight to sentiment\n",
    "        # This could be better updated for modifiers that either positively or negatively emphasize\n",
    "        # can't catch \"there are nowhere near enough loungers\"\n",
    "        if ((child.dep_ == \"amod\") or (child.dep_ == \"advmod\")) and (child.text in opinion_words):\n",
    "            sentiment *= 1.5\n",
    "        # check for negation words and flip the sign of sentiment\n",
    "        if child.dep_ == \"neg\":\n",
    "            sentiment *= -1\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def add_subchild(child, sent_dict, sentiment, token, added):\n",
    "    if child.children == []:\n",
    "        return sent_dict, added\n",
    "    else:\n",
    "        conj = 0\n",
    "        for subchild in child.children:\n",
    "            if (subchild.dep_ in [\"compound\", \"amod\", \"nmod\"]) & (subchild != token):\n",
    "                sent_dict[subchild.lemma_ + ' ' + child.lemma_] += sentiment\n",
    "                for sub in subchild.children:\n",
    "                    if sub.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                        sent_dict[sub.lemma_ + ' ' + child.lemma_] += sentiment\n",
    "                added = True\n",
    "            # check for conjugates (a AND b), then add both to dictionary\n",
    "            elif subchild.text == \"and\" or subchild.text == \",\":\n",
    "                conj += 1\n",
    "        for subchild in child.children:\n",
    "            if (conj > 0) & (subchild.pos_ == \"NOUN\" or subchild.pos_ == \"PROPN\"):\n",
    "                sent_dict = check_compound(subchild, sent_dict, sentiment, child)\n",
    "                conj -= 1\n",
    "    return sent_dict, added\n",
    "\n",
    "\n",
    "def check_compound(child, sent_dict, sentiment, token=None):\n",
    "    added = False\n",
    "    sent_dict, added = add_subchild(child, sent_dict, sentiment, token, added)\n",
    "    if not added:\n",
    "        sent_dict[child.lemma_] += sentiment\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_compound(token, sent_dict, sentiment):\n",
    "    if token.head.dep_ == \"compound\":\n",
    "        sent_dict = for_compound(token.head, sent_dict, sentiment)\n",
    "    elif token.head.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "        sent_dict = check_compound(token.head, sent_dict, sentiment)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_acomp(token, sent_dict, sentiment):\n",
    "    for ancestor in token.ancestors:\n",
    "        if ancestor.dep_ == \"attr\":\n",
    "            sent_dict[ancestor] += sentiment\n",
    "        if ancestor.dep_ in [\"advcl\", \"ROOT\", \"conj\"]:\n",
    "            sent_dict = for_advcl(ancestor, sent_dict, sentiment, token)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_advcl(ancestor, sent_dict, sentiment, token):\n",
    "    for child in ancestor.children:\n",
    "        if (child.dep_ in [\"nsubj\", \"compound\"] ) & (child.pos_ in [\"NOUN\", \"PROPN\"]):\n",
    "            sent_dict = check_compound(child, sent_dict, sentiment, token)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_amod(token, sent_dict, sentiment):\n",
    "    if token.head.dep_ == \"appos\":\n",
    "        sent_dict = check_compound(token.head, sent_dict, sentiment, token)\n",
    "    elif token.head.dep_ == \"pobj\":\n",
    "        if token.head.head.head.dep_ in [\"advcl\", \"ROOT\", \"conj\"]:\n",
    "            sent_dict = for_advcl(token.head.head.head, sent_dict, sentiment, token)\n",
    "    if token.head.pos_ == \"NOUN\" or token.head.pos_ == \"PROPN\":  # token.head.dep_ != \"compound\", so \"free room delivery\" not added twice\n",
    "        sent_dict = check_compound(token.head, sent_dict, sentiment, token)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_dobj(token, sent_dict, sentiment):\n",
    "    if token.head.dep_ == \"conj\":\n",
    "        head = token.head.head\n",
    "        head_child = token.head\n",
    "    else:\n",
    "        head = token.head\n",
    "        head_child = token\n",
    "    for child in head.children:\n",
    "        if (child.dep_ == \"nsubj\") & (child.pos_ == \"NOUN\" or child.pos_ == \"PROPN\"):\n",
    "            sent_dict = check_compound(child, sent_dict, sentiment, head_child)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def for_prep(token, sent_dict, sentiment):\n",
    "    for child in token.children:\n",
    "        if child.pos_ == \"NOUN\" or child.pos_ == \"PROPN\":\n",
    "            sent_dict = check_compound(child, sent_dict, sentiment, token)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def feature_sentiment(sentence):\n",
    "    '''\n",
    "    input: dictionary and sentence\n",
    "    function: appends dictionary with new features if the feature did not exist previously,\n",
    "              then updates sentiment to each of the new or existing features\n",
    "    output: updated dictionary\n",
    "    '''\n",
    "    sent_dict = Counter()\n",
    "    sentence = spacy(sentence)\n",
    "    for token in sentence:\n",
    "        # check if the word is an opinion word, then assign sentiment\n",
    "        if (token.lemma_ in opinion_words) or (token.text in opinion_words):\n",
    "            sentiment = 1 if ((token.text in pos) or (token.lemma_ in pos)) else -1\n",
    "            # if target is an adverb modifier (i.e. pretty, highly, etc.)\n",
    "            # but happens to be an opinion word, ignore and pass\n",
    "            sentiment = modify_sentiment(token, sentiment)\n",
    "            if (token.dep_ == \"advmod\"):\n",
    "                continue\n",
    "            elif (token.dep_ == \"acomp\"):\n",
    "                sent_dict = for_acomp(token, sent_dict, sentiment)\n",
    "            elif (token.dep_ == \"amod\"):\n",
    "                sent_dict = for_amod(token, sent_dict, sentiment)\n",
    "            elif (token.dep_ == \"compound\"):\n",
    "                sent_dict = for_compound(token, sent_dict, sentiment)\n",
    "            elif (token.dep_ == \"dobj\"):\n",
    "                sent_dict = for_dobj(token, sent_dict, sentiment)\n",
    "            elif (token.dep_ == \"relcl\"):\n",
    "                if token.head.pos_ == \"NOUN\" or token.head.pos_ == \"PROPN\":\n",
    "                    sent_dict[token.head.lemma_] += sentiment\n",
    "            else:\n",
    "                    # if verb, check if there's a direct object\n",
    "                if token.head.dep_ == \"advcl\" or token.head.dep_ == \"ROOT\":\n",
    "                    sent_dict = for_advcl(token.head, sent_dict, sentiment, token)\n",
    "                for child in token.children:\n",
    "                    if (token.pos_ == \"VERB\") & (child.dep_ == \"dobj\"):\n",
    "                        sent_dict = check_compound(child, sent_dict, sentiment, token)\n",
    "                    # check for nouns\n",
    "                    elif child.pos_ == \"NOUN\" or child.pos_ == \"PROPN\":\n",
    "                        sent_dict = check_compound(child, sent_dict, sentiment, token)\n",
    "                    if ((token.pos_ == \"VERB\") or (token.pos_ == \"ADJ\")) & (child.dep_ == \"prep\"):\n",
    "                        sent_dict = for_prep(child, sent_dict, sentiment)\n",
    "    return sent_dict\n",
    "\n",
    "\n",
    "def classify_and_sent(sentence, aspect_sent, terms_dict):\n",
    "    '''\n",
    "    function: classify the sentence into a category, and assign sentiment\n",
    "    note: aspect_dict is a parent dictionary with all the aspects\n",
    "    input: sentence & aspect dictionary, which is going to be updated\n",
    "    output: updated aspect dictionary\n",
    "    '''\n",
    "    # classify sentence with NB classifier\n",
    "    predicted = svm_model.predict([sentence])\n",
    "    pred = mlb.inverse_transform(predicted)\n",
    "    if \"('OTHER'),\" in pred:\n",
    "        pred.remove(\"('OTHER'),\")\n",
    "    if \"('NOTRELATED'),\" in pred:\n",
    "        pred.remove(\"('NOTRELATED'),\")\n",
    "\n",
    "    # get aspect names and their sentiment in a dictionary form\n",
    "    sent_dict = feature_sentiment(sentence)\n",
    "\n",
    "    # try to categorize the aspect names into the 4 aspects in aspect_dict\n",
    "    aspect_sent, terms_dict = assign_term_to_aspect(aspect_sent, terms_dict, sent_dict, pred)\n",
    "    return aspect_sent, terms_dict\n",
    "\n",
    "\n",
    "#def replace_pronouns(text):\n",
    " #   coref.one_shot_coref(text)\n",
    "  #  return coref.get_resolved_utterances()[0]\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def split_sentence(text):\n",
    "    '''\n",
    "    splits review into a list of sentences using spacy's sentence parser\n",
    "    '''\n",
    "    review = spacy(text)\n",
    "    bag_sentence = []\n",
    "    start = 0\n",
    "    for token in review:\n",
    "        if token.sent_start:\n",
    "            bag_sentence.append(review[start:(token.i - 1)])\n",
    "            start = token.i\n",
    "        if token.i == len(review) - 1:\n",
    "            bag_sentence.append(review[start:(token.i + 1)])\n",
    "    return bag_sentence\n",
    "\n",
    "# Remove special characters using regex\n",
    "def remove_special_char(sentence):\n",
    "    return re.sub(r\"[^a-zA-Z0-9.',:;?]+\", ' ', sentence)\n",
    "# \"ROOMS\", \"CLEANLINESS\", \"VALUE\", \"SERVICE\", \"LOCATION\", \"CHECKIN\", \"BUSINESS\", \"FOOD\", \"BUILDING\", \"OTHER\", \"NOTRELATED\"\n",
    "def review_pipe(review, aspect_sent, terms_dict):\n",
    "    #review = replace_pronouns(review)\n",
    "    sentences = split_sentence(review)\n",
    "    for sentence in sentences:\n",
    "        sentence = remove_special_char(str(sentence))\n",
    "        aspect_sent, terms_dict = classify_and_sent(sentence.lower(), aspect_sent, terms_dict)\n",
    "    return aspect_sent, terms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below if running for first time.\n",
    "# Setup nltk corpora path and Google Word2Vec location\n",
    "#google_vec_file = 'GoogleNews-vectors-negative300.bin'\n",
    "#word2vec = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)\n",
    "#pickle.dump(word2vec, open(\"word2vec_google.pkl\", 'wb'))\n",
    "\n",
    "# If above script has been run, load saved word embedding\n",
    "word2vec = pickle.load(open(\"word2vec_google.pkl\", 'rb'))\n",
    "\n",
    "# load the Multi-label binarizer from previous notebook\n",
    "mlb = pickle.load(open(\"mlb.pkl\", 'rb'))\n",
    "\n",
    "# load the fitted naive bayes model from previous notebook\n",
    "svm_model = pickle.load(open(\"svm_model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hotel_reviewVA.txt\") as fp: \n",
    "    reviews = []\n",
    "    Lines = fp.readlines() \n",
    "    for line in Lines: \n",
    "        reviews.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention not in vocab\n",
      "rimmed glass not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "order not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      ". location not in vocab\n",
      "n.o location not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "callaisgeneral manager not in vocab\n",
      "air con not in vocab\n",
      "-PRON- not in vocab\n",
      "russells not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "callaisgeneral manager not in vocab\n",
      "advice not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "callaisgeneral manager not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "sheet not in vocab\n",
      "addition not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "callaisgeneral manager not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "smallness not in vocab\n",
      "saint game not in vocab\n",
      "pm not in vocab\n",
      "-PRON- not in vocab\n",
      "2800 not in vocab\n",
      "one not in vocab\n",
      "last day not in vocab\n",
      "movie not in vocab\n",
      "one not in vocab\n",
      "-PRON- not in vocab\n",
      "long hair not in vocab\n",
      "brown hair not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "sink not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "exception not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "estes condos not in vocab\n",
      "dvd player not in vocab\n",
      "-PRON- not in vocab\n",
      "walk not in vocab\n",
      "drury suites not in vocab\n",
      "stay not in vocab\n",
      "finish not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "pull not in vocab\n",
      "-PRON- not in vocab\n",
      "sunday morning not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "marriot member not in vocab\n",
      "-PRON- service not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "issue not in vocab\n",
      "fight not in vocab\n",
      "-PRON- not in vocab\n",
      "review not in vocab\n",
      "-PRON- not in vocab\n",
      "centre not in vocab\n",
      "squeeze orangejuice not in vocab\n",
      "fascilitie not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "12th check not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "light not in vocab\n",
      "usual switch not in vocab\n",
      "same drip not in vocab\n",
      "drip drip not in vocab\n",
      "sheraton not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "jgfront manager not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "sheraton hotel not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "lbgeneral manager not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "sheraton not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "acknowledgement not in vocab\n",
      "-PRON- not in vocab\n",
      "youjonathan not in vocab\n",
      "gerberfront not in vocab\n",
      "youjgfront manager not in vocab\n",
      "appearance not in vocab\n",
      "-PRON- not in vocab\n",
      "-PRON- not in vocab\n",
      "herd not in vocab\n",
      "-PRON- not in vocab\n",
      "th issue not in vocab\n",
      "-PRON- not in vocab\n",
      "air not in vocab\n",
      "-PRON- not in vocab\n",
      "order not in vocab\n",
      "wind chill not in vocab\n"
     ]
    }
   ],
   "source": [
    "aspect_sent={'LOCATION':Counter(), 'CHECKIN':Counter(), 'FOOD':Counter(), 'BUILDING':Counter(), 'ROOM':Counter(), 'CLEANLINESS':Counter(), 'VALUE':Counter(), 'SERVICE':Counter(), 'BUSINESS':Counter(), 'OTHER':Counter()}\n",
    "term_dict={'LOCATION':Counter(), 'CHECKIN':Counter(), 'FOOD':Counter(), 'BUILDING':Counter(), 'ROOM':Counter(), 'CLEANLINESS':Counter(), 'VALUE':Counter(), 'SERVICE':Counter(), 'BUSINESS':Counter(), 'OTHER':Counter()}\n",
    "for review in reviews:\n",
    "    aspect_sent, term_dict = review_pipe(review, aspect_sent, term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aspect, pos, neg = [], [], []\n",
    "for k, v in aspect_sent.items():\n",
    "    aspect.append(k)\n",
    "    pos.append(v['pos'])\n",
    "    neg.append(v['neg'])\n",
    "df = pd.DataFrame({'aspect': aspect, 'pos': pos, 'neg': neg})\n",
    "df['rate'] = (df['pos'] - df['neg']) * 5 / (df['pos'] + df['neg'])\n",
    "df.to_csv('VA_aspect_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "lowest = defaultdict()\n",
    "highest = defaultdict()\n",
    "for i in term_dict:\n",
    "    if term_dict[i]:\n",
    "        highest[i] = term_dict[i].most_common()[:10]\n",
    "        lowest[i] = term_dict[i].most_common()[-10:]\n",
    "highest_df = pd.DataFrame(highest)\n",
    "lowest_df = pd.DataFrame(lowest)\n",
    "lowest_df = lowest_df.drop([\"OTHER\"],1)\n",
    "highest_df = highest_df.drop([\"OTHER\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>CHECKIN</th>\n",
       "      <th>FOOD</th>\n",
       "      <th>BUILDING</th>\n",
       "      <th>ROOM</th>\n",
       "      <th>CLEANLINESS</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SERVICE</th>\n",
       "      <th>BUSINESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(location, 21)</td>\n",
       "      <td>(feedback, 16.5)</td>\n",
       "      <td>(breakfast, 13)</td>\n",
       "      <td>(city, 4)</td>\n",
       "      <td>(room, 31.5)</td>\n",
       "      <td>(clean parking, 3)</td>\n",
       "      <td>(value, 6)</td>\n",
       "      <td>(staff, 43.0)</td>\n",
       "      <td>(bank, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(visit, 13)</td>\n",
       "      <td>(kind word, 6)</td>\n",
       "      <td>(food, 7)</td>\n",
       "      <td>(property, 3.5)</td>\n",
       "      <td>(hotel, 24.5)</td>\n",
       "      <td>(fitness center, 2.5)</td>\n",
       "      <td>(price, 4)</td>\n",
       "      <td>(service, 15)</td>\n",
       "      <td>(continue patronage, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(close location, 4)</td>\n",
       "      <td>(casey manager, 4)</td>\n",
       "      <td>(restaurant, 7.0)</td>\n",
       "      <td>(efficient parking, 3)</td>\n",
       "      <td>(bed, 21.5)</td>\n",
       "      <td>(luxurious amenity, 2.5)</td>\n",
       "      <td>(overall value, 3)</td>\n",
       "      <td>(experience, 7)</td>\n",
       "      <td>(job, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(place, 3)</td>\n",
       "      <td>(valet, 4)</td>\n",
       "      <td>(dinner, 4)</td>\n",
       "      <td>(hvac, 3.0)</td>\n",
       "      <td>(bathroom, 5.5)</td>\n",
       "      <td>(cleanliness, 2)</td>\n",
       "      <td>(great value, 2)</td>\n",
       "      <td>(review, 6)</td>\n",
       "      <td>(office manager, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(view, 3)</td>\n",
       "      <td>(wi fi, 4)</td>\n",
       "      <td>(coffee, 4)</td>\n",
       "      <td>(bank vault, 2)</td>\n",
       "      <td>(pillow, 5)</td>\n",
       "      <td>(amenity, 2)</td>\n",
       "      <td>(correct price, 1.5)</td>\n",
       "      <td>(customer service, 5)</td>\n",
       "      <td>(vibrant art, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(walk, 2)</td>\n",
       "      <td>(wi, 4)</td>\n",
       "      <td>(drink, 4)</td>\n",
       "      <td>(park condos, 2)</td>\n",
       "      <td>(hour, 5)</td>\n",
       "      <td>(noise, 1.5)</td>\n",
       "      <td>(pricing, 1)</td>\n",
       "      <td>(a. manager, 4)</td>\n",
       "      <td>(prestigious bank, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(living area, 2)</td>\n",
       "      <td>(free fi, 3)</td>\n",
       "      <td>(variety, 2.5)</td>\n",
       "      <td>(architectural detail, 1)</td>\n",
       "      <td>(suite, 4)</td>\n",
       "      <td>(ambience, 1)</td>\n",
       "      <td>(knowledge, 1)</td>\n",
       "      <td>(free, 4)</td>\n",
       "      <td>(new experience, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(choice, 2)</td>\n",
       "      <td>(fun, 2)</td>\n",
       "      <td>(continental breakfast, 2)</td>\n",
       "      <td>(fountain, 1)</td>\n",
       "      <td>(towel, 4)</td>\n",
       "      <td>(high level, 1)</td>\n",
       "      <td>(future expectation, 1)</td>\n",
       "      <td>(game traffic, 2.5)</td>\n",
       "      <td>(marketplace, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(great location, 2)</td>\n",
       "      <td>(honest feedback, 2)</td>\n",
       "      <td>(new restaurant, 2)</td>\n",
       "      <td>(street, 1)</td>\n",
       "      <td>(desk staff, 4)</td>\n",
       "      <td>(safe, 1)</td>\n",
       "      <td>(side, 1)</td>\n",
       "      <td>(care, 2)</td>\n",
       "      <td>(transaction, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(size, 1.5)</td>\n",
       "      <td>(orleans experience, 1)</td>\n",
       "      <td>(many restaurant, 2)</td>\n",
       "      <td>(parking lot, 1)</td>\n",
       "      <td>(valet parking, 4)</td>\n",
       "      <td>(kind regard, 1)</td>\n",
       "      <td>(cost, 1)</td>\n",
       "      <td>(excellent service, 2)</td>\n",
       "      <td>(work bank, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LOCATION                  CHECKIN                        FOOD  \\\n",
       "0       (location, 21)         (feedback, 16.5)             (breakfast, 13)   \n",
       "1          (visit, 13)           (kind word, 6)                   (food, 7)   \n",
       "2  (close location, 4)       (casey manager, 4)           (restaurant, 7.0)   \n",
       "3           (place, 3)               (valet, 4)                 (dinner, 4)   \n",
       "4            (view, 3)               (wi fi, 4)                 (coffee, 4)   \n",
       "5            (walk, 2)                  (wi, 4)                  (drink, 4)   \n",
       "6     (living area, 2)             (free fi, 3)              (variety, 2.5)   \n",
       "7          (choice, 2)                 (fun, 2)  (continental breakfast, 2)   \n",
       "8  (great location, 2)     (honest feedback, 2)         (new restaurant, 2)   \n",
       "9          (size, 1.5)  (orleans experience, 1)        (many restaurant, 2)   \n",
       "\n",
       "                    BUILDING                ROOM               CLEANLINESS  \\\n",
       "0                  (city, 4)        (room, 31.5)        (clean parking, 3)   \n",
       "1            (property, 3.5)       (hotel, 24.5)     (fitness center, 2.5)   \n",
       "2     (efficient parking, 3)         (bed, 21.5)  (luxurious amenity, 2.5)   \n",
       "3                (hvac, 3.0)     (bathroom, 5.5)          (cleanliness, 2)   \n",
       "4            (bank vault, 2)         (pillow, 5)              (amenity, 2)   \n",
       "5           (park condos, 2)           (hour, 5)              (noise, 1.5)   \n",
       "6  (architectural detail, 1)          (suite, 4)             (ambience, 1)   \n",
       "7              (fountain, 1)          (towel, 4)           (high level, 1)   \n",
       "8                (street, 1)     (desk staff, 4)                 (safe, 1)   \n",
       "9           (parking lot, 1)  (valet parking, 4)          (kind regard, 1)   \n",
       "\n",
       "                     VALUE                 SERVICE                 BUSINESS  \n",
       "0               (value, 6)           (staff, 43.0)                (bank, 2)  \n",
       "1               (price, 4)           (service, 15)  (continue patronage, 2)  \n",
       "2       (overall value, 3)         (experience, 7)                 (job, 2)  \n",
       "3         (great value, 2)             (review, 6)      (office manager, 2)  \n",
       "4     (correct price, 1.5)   (customer service, 5)         (vibrant art, 1)  \n",
       "5             (pricing, 1)         (a. manager, 4)    (prestigious bank, 1)  \n",
       "6           (knowledge, 1)               (free, 4)      (new experience, 1)  \n",
       "7  (future expectation, 1)     (game traffic, 2.5)         (marketplace, 1)  \n",
       "8                (side, 1)               (care, 2)         (transaction, 1)  \n",
       "9                (cost, 1)  (excellent service, 2)           (work bank, 1)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>CHECKIN</th>\n",
       "      <th>FOOD</th>\n",
       "      <th>BUILDING</th>\n",
       "      <th>ROOM</th>\n",
       "      <th>CLEANLINESS</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SERVICE</th>\n",
       "      <th>BUSINESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(neighborhood, 1)</td>\n",
       "      <td>(new arrival, 1)</td>\n",
       "      <td>(friendly atmosphere, 0)</td>\n",
       "      <td>(street, 1)</td>\n",
       "      <td>(low room, -2)</td>\n",
       "      <td>(high level, 1)</td>\n",
       "      <td>(side, 1)</td>\n",
       "      <td>(maintenance guy, -1)</td>\n",
       "      <td>(vibrant art, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(surround area, 1)</td>\n",
       "      <td>(heather gordon, 1)</td>\n",
       "      <td>(good atmosphere, 0)</td>\n",
       "      <td>(parking lot, 1)</td>\n",
       "      <td>(light room, -2)</td>\n",
       "      <td>(safe, 1)</td>\n",
       "      <td>(cost, 1)</td>\n",
       "      <td>(woman, -1)</td>\n",
       "      <td>(prestigious bank, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(light selection, 1)</td>\n",
       "      <td>(denny, 1)</td>\n",
       "      <td>(item, -1)</td>\n",
       "      <td>(entrance, -1)</td>\n",
       "      <td>(carpeting, -2)</td>\n",
       "      <td>(kind regard, 1)</td>\n",
       "      <td>(rate, 1)</td>\n",
       "      <td>(note, -1)</td>\n",
       "      <td>(new experience, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(many place, 0)</td>\n",
       "      <td>(diego tip, 1)</td>\n",
       "      <td>(water glass, -1)</td>\n",
       "      <td>(exercise equipment, -1)</td>\n",
       "      <td>(floor room, -2)</td>\n",
       "      <td>(housekeeping staff, 1)</td>\n",
       "      <td>(what, 1)</td>\n",
       "      <td>(child, -1)</td>\n",
       "      <td>(marketplace, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(other place, 0)</td>\n",
       "      <td>(san tip, 1)</td>\n",
       "      <td>(only disappointment, -1)</td>\n",
       "      <td>(major road, -1)</td>\n",
       "      <td>(bed room, -2)</td>\n",
       "      <td>(decor, 1)</td>\n",
       "      <td>(review, 1)</td>\n",
       "      <td>(surprise, -1)</td>\n",
       "      <td>(transaction, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(town atmosphere, 0)</td>\n",
       "      <td>(thompson river, 0)</td>\n",
       "      <td>(old bedding, -1)</td>\n",
       "      <td>(part, -1)</td>\n",
       "      <td>(king room, -2)</td>\n",
       "      <td>(amenity caddy, 1)</td>\n",
       "      <td>(option, 1)</td>\n",
       "      <td>(courtesy shuttle, -1)</td>\n",
       "      <td>(work bank, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(attractive place, -1)</td>\n",
       "      <td>(wifi, 0)</td>\n",
       "      <td>(meal, -1)</td>\n",
       "      <td>(parking, -1)</td>\n",
       "      <td>(door, -2)</td>\n",
       "      <td>(pride, 1)</td>\n",
       "      <td>(amount, -1)</td>\n",
       "      <td>(only inconvenience, -2)</td>\n",
       "      <td>(business district, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(facility, -1)</td>\n",
       "      <td>(katrina, -1)</td>\n",
       "      <td>(big river, -1)</td>\n",
       "      <td>(mountain park, -1)</td>\n",
       "      <td>(kitchen area, -2)</td>\n",
       "      <td>(traffic noise, -1)</td>\n",
       "      <td>(monetary limit, -1)</td>\n",
       "      <td>(traffic, -2)</td>\n",
       "      <td>(central, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(only problem, -1)</td>\n",
       "      <td>(jared, -1)</td>\n",
       "      <td>(pasta, -1)</td>\n",
       "      <td>(the, -1)</td>\n",
       "      <td>(window, -2)</td>\n",
       "      <td>(noise level, -1)</td>\n",
       "      <td>(several opportunity, -1)</td>\n",
       "      <td>(ac, -2)</td>\n",
       "      <td>(great job, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(difficult access, -2)</td>\n",
       "      <td>(tv, -2)</td>\n",
       "      <td>(water, -3)</td>\n",
       "      <td>(condo, -2)</td>\n",
       "      <td>(room service, -3)</td>\n",
       "      <td>(smallness inconvenience, -2)</td>\n",
       "      <td>(expectation, -4)</td>\n",
       "      <td>(c unit, -2)</td>\n",
       "      <td>(business, -1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LOCATION              CHECKIN                       FOOD  \\\n",
       "0       (neighborhood, 1)     (new arrival, 1)   (friendly atmosphere, 0)   \n",
       "1      (surround area, 1)  (heather gordon, 1)       (good atmosphere, 0)   \n",
       "2    (light selection, 1)           (denny, 1)                 (item, -1)   \n",
       "3         (many place, 0)       (diego tip, 1)          (water glass, -1)   \n",
       "4        (other place, 0)         (san tip, 1)  (only disappointment, -1)   \n",
       "5    (town atmosphere, 0)  (thompson river, 0)          (old bedding, -1)   \n",
       "6  (attractive place, -1)            (wifi, 0)                 (meal, -1)   \n",
       "7          (facility, -1)        (katrina, -1)            (big river, -1)   \n",
       "8      (only problem, -1)          (jared, -1)                (pasta, -1)   \n",
       "9  (difficult access, -2)             (tv, -2)                (water, -3)   \n",
       "\n",
       "                   BUILDING                ROOM  \\\n",
       "0               (street, 1)      (low room, -2)   \n",
       "1          (parking lot, 1)    (light room, -2)   \n",
       "2            (entrance, -1)     (carpeting, -2)   \n",
       "3  (exercise equipment, -1)    (floor room, -2)   \n",
       "4          (major road, -1)      (bed room, -2)   \n",
       "5                (part, -1)     (king room, -2)   \n",
       "6             (parking, -1)          (door, -2)   \n",
       "7       (mountain park, -1)  (kitchen area, -2)   \n",
       "8                 (the, -1)        (window, -2)   \n",
       "9               (condo, -2)  (room service, -3)   \n",
       "\n",
       "                     CLEANLINESS                      VALUE  \\\n",
       "0                (high level, 1)                  (side, 1)   \n",
       "1                      (safe, 1)                  (cost, 1)   \n",
       "2               (kind regard, 1)                  (rate, 1)   \n",
       "3        (housekeeping staff, 1)                  (what, 1)   \n",
       "4                     (decor, 1)                (review, 1)   \n",
       "5             (amenity caddy, 1)                (option, 1)   \n",
       "6                     (pride, 1)               (amount, -1)   \n",
       "7            (traffic noise, -1)       (monetary limit, -1)   \n",
       "8              (noise level, -1)  (several opportunity, -1)   \n",
       "9  (smallness inconvenience, -2)          (expectation, -4)   \n",
       "\n",
       "                    SERVICE                BUSINESS  \n",
       "0     (maintenance guy, -1)        (vibrant art, 1)  \n",
       "1               (woman, -1)   (prestigious bank, 1)  \n",
       "2                (note, -1)     (new experience, 1)  \n",
       "3               (child, -1)        (marketplace, 1)  \n",
       "4            (surprise, -1)        (transaction, 1)  \n",
       "5    (courtesy shuttle, -1)          (work bank, 1)  \n",
       "6  (only inconvenience, -2)  (business district, 1)  \n",
       "7             (traffic, -2)            (central, 1)  \n",
       "8                  (ac, -2)          (great job, 1)  \n",
       "9              (c unit, -2)          (business, -1)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
